# Transformer_Vision

![Vision Transformer](vision_transformer.png)

## Papers ğŸ“„
I am reading these papers:

### Transformer Original Paper:
â˜‘ï¸ [**Attention is All You Need (NIPS 2017)**](https://arxiv.org/abs/1706.03762)

### Distillation Papers:
â˜‘ï¸ [**DeiT (Data-efficient Image Transformers)**](https://arxiv.org/abs/2012.12877)
â˜‘ï¸ [**Efficient Vision Transformers via Fine-Grained Manifold Distillation**](https://arxiv.org/abs/2107.01378)
â˜‘ï¸ [**NViT (Vision Transformer Compression and Parameter Redistribution)**](https://arxiv.org/abs/2110.04869)
â˜‘ï¸ [**SiT (Self-slimmed Vision Transformer)**](https://arxiv.org/abs/2111.12624)

## Goals ğŸ¯

â˜‘ï¸ Develop and implement vision transformer models, including foundational architectures like ViT and DeiT, as well as advanced variants.
â˜‘ï¸ Investigate and apply different distillation methods to improve the efficiency and performance of vision transformers.
â˜‘ï¸ Design and execute benchmark tests to assess and compare the performance of various vision transformer models on diverse datasets.
â˜‘ï¸ Implement optimization techniques such as pruning, quantization, and advanced distillation methods to reduce model size and increase inference speed.
â˜‘ï¸ Develop comprehensive tutorials and example notebooks to facilitate understanding and practical use of vision transformers for different projects.
â˜‘ï¸ Fine-tune and evaluate vision transformers for specific real-world scenarios, including medical imaging, autonomous driving, and remote sensing applications.


